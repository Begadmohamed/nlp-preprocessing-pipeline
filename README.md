# nlp-preprocessing-pipeline
A simple NLP preprocessing pipeline using NLTK and SpaCy. Includes tokenization, stopword removal, stemming, lemmatization, POS tagging, and named entity recognition, applied to a set of movie reviews. Results are exported to CSV for analysis.
# NLP Preprocessing Pipeline

This project demonstrates the essential steps of Natural Language Processing (NLP) text preprocessing using **NLTK** and **SpaCy**.  
The dataset consists of short movie reviews, and the pipeline prepares the text for further analysis or machine learning tasks.

---

## üìå Features
- **Tokenization**: Split text into individual words.
- **Stopword Removal**: Remove common irrelevant words (e.g., *the, is, and*).
- **Stemming & Lemmatization**: Normalize words to their base/root forms.
- **Part-of-Speech (POS) Tagging**: Assign grammatical tags to each word.
- **Named Entity Recognition (NER)**: Extract entities such as people, places, and organizations.
- **CSV Export**: Save results for later analysis.

---

## üõ†Ô∏è Tools & Libraries
- [Python 3](https://www.python.org/)
- [NLTK](https://www.nltk.org/)
- [SpaCy](https://spacy.io/)

---

## üöÄ Usage

1. Clone this repository:
   ```bash
   git clone https://github.com/your-username/nlp-preprocessing-pipeline.git
   cd nlp-preprocessing-pipeline
